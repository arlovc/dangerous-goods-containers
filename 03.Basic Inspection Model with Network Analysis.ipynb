{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pycountry\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy as copy\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.calibration import CalibratedClassifierCV as CCCV\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold as SKF\n",
    "from sklearn.metrics import precision_score, roc_auc_score, average_precision_score\n",
    "import re\n",
    "import warnings\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "# Initialize tqdm for pandas\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()\n",
    "plt.style.use(\"dark_background\")\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for model training and visualization\n",
    "def make_results_df(X, y, n_folds=10, base_estimator=RFC(n_estimators=500, random_state=42, n_jobs=-1)):\n",
    "    skf = SKF(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    results_df = pd.DataFrame(data=y, columns=[\"y\"])\n",
    "    results_df[\"y\"] = results_df[\"y\"].astype(str)\n",
    "    fold_counter = 1\n",
    "    for train_index, test_index in tqdm(skf.split(X, y), desc=\"folds\"):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = CCCV(base_estimator=base_estimator, cv=skf, n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "        results_df.loc[test_index, \"prob\"] = y_prob\n",
    "        results_df.loc[test_index, \"fold\"] = str(fold_counter)\n",
    "        fold_counter += 1\n",
    "    return results_df\n",
    "\n",
    "# Additional visualization functions\n",
    "\n",
    "def plot_results(results_df, common_norm=True):\n",
    "    \"\"\"\n",
    "    Plots the distribution of predicted probabilities for each class in the dataset.\n",
    "    \"\"\"\n",
    "    sb.histplot(\n",
    "        results_df,\n",
    "        x=\"prob\",\n",
    "        hue=\"y\",\n",
    "        element=\"step\",\n",
    "        common_norm=common_norm,\n",
    "        palette=\"Set2\",\n",
    "        bins=20,\n",
    "    )\n",
    "    plt.title(\"Predicted probabilities per class\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_precisions(results_df):\n",
    "    \"\"\"\n",
    "    Plots the precision for different probability thresholds for each fold.\n",
    "    \"\"\"\n",
    "    thresholds = np.arange(0, 1.1, 0.1)\n",
    "    precisions = []\n",
    "    for fold in results_df[\"fold\"].unique():\n",
    "        fold_results = results_df[results_df[\"fold\"] == fold]\n",
    "        fold_precisions = [\n",
    "            precision_score(fold_results[\"y\"], fold_results[\"prob\"] > threshold)\n",
    "            for threshold in thresholds\n",
    "        ]\n",
    "        precisions.append(fold_precisions)\n",
    "    precisions = np.array(precisions)\n",
    "    avg_precisions = precisions.mean(axis=0)\n",
    "\n",
    "    plt.plot(thresholds, avg_precisions, marker=\"o\", label=\"Average precision\")\n",
    "    for fold_idx, fold_prec in enumerate(precisions):\n",
    "        plt.plot(thresholds, fold_prec, alpha=0.5, linestyle=\"--\", label=f\"Fold {fold_idx + 1}\")\n",
    "    plt.xlabel(\"Probability threshold\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision by Threshold per Fold\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_aucs(results_df):\n",
    "    \"\"\"\n",
    "    Plots the AUC (Area Under Curve) for each fold and overall.\n",
    "    \"\"\"\n",
    "    aucs = []\n",
    "    for fold in results_df[\"fold\"].unique():\n",
    "        fold_results = results_df[results_df[\"fold\"] == fold]\n",
    "        auc = roc_auc_score(fold_results[\"y\"].astype(int), fold_results[\"prob\"])\n",
    "        aucs.append(auc)\n",
    "\n",
    "    plt.bar(range(1, len(aucs) + 1), aucs, alpha=0.7, label=\"AUC per fold\")\n",
    "    plt.axhline(y=np.mean(aucs), color=\"r\", linestyle=\"--\", label=\"Average AUC\")\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.title(\"AUC per Fold and Average AUC\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load datasets\n",
    "df = pd.read_csv(\"../data/Douane_with_holmes_outcomes_unfolded_20230120.csv\")\n",
    "dfn = pd.read_csv(\"../data/DMF_for_networks_and_undummied.csv\")\n",
    "df.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "\n",
    "# Preprocessing: Create a unique key and drop duplicates\n",
    "dfn['unique_key'] = dfn['EQP_NUMMER'] + '__' + dfn['AANKOMSTDATUM']\n",
    "dfn.drop_duplicates('unique_key', keep='first', inplace=True)\n",
    "\n",
    "# Filter relevant columns based on patterns\n",
    "good_cols = ['NAAM', 'unique_key', 'AANKOMSTDATUM']\n",
    "to_keep = [col for col in dfn.columns.tolist() if any(re.search(pattern, col) for pattern in good_cols)]\n",
    "dfn = dfn[to_keep]\n",
    "\n",
    "# Handle missing values\n",
    "dfn.loc[dfn['NAAM_KG'].isnull(), 'NAAM_KG'] = 'MISSING_KG'\n",
    "dfn.loc[dfn['NAAM_VG'].isnull(), 'NAAM_VG'] = 'MISSING_VG'\n",
    "dfn.loc[dfn['NAAM_OG'].isnull(), 'NAAM_OG'] = 'MISSING_OG'\n",
    "dfn.loc[dfn['NAAM_KG'] == 'SAME AS CONSIGNEE', 'NAAM_KG'] = dfn.loc[dfn['NAAM_KG'] == 'SAME AS CONSIGNEE', 'NAAM_OG']\n",
    "\n",
    "# Build a network graph from data columns\n",
    "G = nx.from_pandas_edgelist(dfn[['NAAM_VG', 'NAAM_OG', 'NAAM_KG', 'NAAM_VV', 'NAAM_VM']], 'NAAM_VM', 'NAAM_VG')\n",
    "list_ots = ['NAAM_OG', 'NAAM_KG', 'NAAM_VV']\n",
    "for ots in list_ots:\n",
    "    G.add_edges_from(zip(dfn['NAAM_VM'], dfn[ots]))\n",
    "\n",
    "# Generate node embeddings using Node2Vec\n",
    "node2vec = Node2Vec(G, dimensions=16, walk_length=128, num_walks=10, workers=4, p=1, q=0.5)\n",
    "mdl = node2vec.fit(vector_size=16, window=10, min_count=1)\n",
    "emb_df = pd.DataFrame([mdl.wv.get_vector(str(n)) for n in G.nodes()], index=G.nodes)\n",
    "\n",
    "# Multiply embeddings for feature aggregation\n",
    "emb_dict = emb_df.to_dict(orient='index')\n",
    "list_of_results = []\n",
    "for _, row in dfn.iterrows():\n",
    "    result = np.multiply(emb_dict[row['NAAM_VG']].values(), emb_dict[row['NAAM_KG']].values())\n",
    "    result = np.multiply(result, emb_dict[row['NAAM_OG']].values())\n",
    "    result = np.multiply(result, emb_dict[row['NAAM_VM']].values())\n",
    "    result = np.multiply(result, emb_dict[row['NAAM_VV']].values())\n",
    "    list_of_results.append(result)\n",
    "\n",
    "# Prepare final dataframe for model training\n",
    "resdf = pd.DataFrame(list_of_results)\n",
    "new_cols = ['emb_' + str(col) for col in resdf.columns]\n",
    "resdf.columns = new_cols\n",
    "for col in resdf:\n",
    "    dfn[col] = resdf[col]\n",
    "\n",
    "dfn.set_index('unique_key', inplace=True)\n",
    "df['unique_key'] = df['EQP_NUMMER'] + '__' + df['AANKOMSTDATUM']\n",
    "df.set_index('unique_key', inplace=True)\n",
    "df_final = pd.merge(df, dfn, left_index=True, right_index=True)\n",
    "df_final.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Process and encode trade type based on origin and destination\n",
    "df[\"trade_type\"] = df[[\"Prisma_incoming_country_origin\", \"Prisma_incoming_country_destination\"]].apply(lambda row: \"import\" if row[1] == \"Netherlands\" else (\"export\" if row[0] == \"Netherlands\" else \"transit\"), axis=1)\n",
    "columns = df.columns.tolist()\n",
    "columns[-1] = \"target\"\n",
    "columns[-2] = \"trade_type\"\n",
    "df = df[columns]\n",
    "\n",
    "# Train and evaluate the model for non-compliance and compliance detection\n",
    "X_columns = df.columns[2:-1]\n",
    "y_column = df.columns[-1]\n",
    "X = pd.get_dummies(df[X_columns]).values\n",
    "y = df[y_column].values\n",
    "results_df = make_results_df(X, y, n_folds=10)\n",
    "plot_results(results_df, common_norm=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python my_stuff",
   "language": "python",
   "name": "my_stuff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
